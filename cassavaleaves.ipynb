{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpxKLnHzkNqO"
      },
      "source": [
        "IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c548b175"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwwL4sEsdWl3"
      },
      "source": [
        "MOUNTIING THE DRIVE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4PC1T-SYLDn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wofdcuqkjoi"
      },
      "source": [
        "EXTRACTING THE FILE (DATASET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJIST2Ewgg-Y"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the zip file in your Google Drive\n",
        "zip_path = '/content/drive/MyDrive/ML PROJECTS/archive.zip'\n",
        "\n",
        "# Define the directory where you want to extract the contents\n",
        "extract_path = '/content/'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Open the zip file in read mode\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # Extract all the contents into the specified directory\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sVqXtqUkxHk"
      },
      "source": [
        "FOLDERS EXTRACTED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d01a1b51"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# List the files in the extraction directory\n",
        "extracted_files = os.listdir('/content/')\n",
        "\n",
        "print(\"Files extracted:\")\n",
        "for file in extracted_files:\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfVd5dl_lQpG"
      },
      "source": [
        "List the files within the 'WHITEFLY' and 'HEALTHY' directories to see the image filenames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d26d30b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "whitefly_dir = '/content/kkkk/Whitefly'\n",
        "healthy_dir = '/content/kkkk/Healthy'\n",
        "\n",
        "whitefly_files = os.listdir(whitefly_dir)\n",
        "healthy_files = os.listdir(healthy_dir)\n",
        "\n",
        "print(\"Files in Whitefly directory:\")\n",
        "for file in whitefly_files:\n",
        "    print(file)\n",
        "\n",
        "print(\"\\nFiles in Healthy directory:\")\n",
        "for file in healthy_files:\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V9XNuMtmAa2"
      },
      "source": [
        "FILES IN EACH FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0iI223ElcdG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Assuming the 'whitefly_dir' and 'healthy_dir' variables are already defined\n",
        "# If not, you would need to define them here:\n",
        "whitefly_dir = '/content/kkkk/Whitefly'\n",
        "healthy_dir = '/content/kkkk/Healthy'\n",
        "\n",
        "\n",
        "# List the files in each directory\n",
        "whitefly_files = os.listdir(whitefly_dir)\n",
        "healthy_files = os.listdir(healthy_dir)\n",
        "\n",
        "# Count the number of files\n",
        "num_whitefly_files = len(whitefly_files)\n",
        "num_healthy_files = len(healthy_files)\n",
        "\n",
        "print(f\"Number of files in Whitefly directory: {num_whitefly_files}\")\n",
        "print(f\"\\nNumber of files in Healthy directory: {num_healthy_files}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA_abAOgmPcg"
      },
      "source": [
        "DISPLAYING SAMPLE IMAGES FOR EACH FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "515145af"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Assuming the 'whitefly_dir' and 'healthy_dir' variables are already defined\n",
        "# from the previous step where we listed the files.\n",
        "# If not, you would need to define them here:\n",
        "# whitefly_dir = '/content/kkkk/Whitefly'\n",
        "# healthy_dir = '/content/kkkk/Healthy'\n",
        "\n",
        "# Get the list of files again in case the kernel was reset\n",
        "whitefly_files = os.listdir(whitefly_dir)\n",
        "healthy_files = os.listdir(healthy_dir)\n",
        "\n",
        "\n",
        "# Define paths to a few sample images (taking the first 3 from each list)\n",
        "sample_whitefly_images = [\n",
        "    os.path.join(whitefly_dir, whitefly_files[0]),\n",
        "    os.path.join(whitefly_dir, whitefly_files[1]),\n",
        "    os.path.join(whitefly_dir, whitefly_files[2])\n",
        "]\n",
        "\n",
        "sample_healthy_images = [\n",
        "    os.path.join(healthy_dir, healthy_files[0]),\n",
        "    os.path.join(healthy_dir, healthy_files[1]),\n",
        "    os.path.join(healthy_dir, healthy_files[2])\n",
        "]\n",
        "\n",
        "# Create a figure and subplots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(10, 7)) # 2 rows for categories, 3 columns for images\n",
        "\n",
        "# Display sample whitefly images\n",
        "for i, img_path in enumerate(sample_whitefly_images):\n",
        "    img = Image.open(img_path)\n",
        "    axes[0, i].imshow(img)\n",
        "    axes[0, i].set_title('Whitefly')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "# Display sample healthy images\n",
        "for i, img_path in enumerate(sample_healthy_images):\n",
        "    img = Image.open(img_path)\n",
        "    axes[1, i].imshow(img)\n",
        "    axes[1, i].set_title('Healthy')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScjshEtPoQFI"
      },
      "source": [
        "DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2c31d20"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def load_and_preprocess_images(directory, target_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses images from a directory, handling corrupted files.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Path to the directory containing images.\n",
        "        target_size (tuple): Desired size for resizing images (width, height).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of preprocessed image arrays.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img = img.resize(target_size)\n",
        "            img_array = np.array(img)\n",
        "            images.append(img_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading or processing image: {filename} - {e}\")\n",
        "            continue\n",
        "    return images\n",
        "\n",
        "# Assuming the 'healthy_dir' and 'whitefly_dir' variables are already defined\n",
        "# from the previous step where we listed the files.\n",
        "# If not, you would need to define them here:\n",
        "# whitefly_dir = '/content/kkkk/Whitefly'\n",
        "# healthy_dir = '/content/kkkk/Healthy'\n",
        "\n",
        "# Load images from the directories\n",
        "healthy_images = load_and_preprocess_images(healthy_dir)\n",
        "whitefly_images = load_and_preprocess_images(whitefly_dir)\n",
        "\n",
        "# Create labels for each category\n",
        "healthy_labels = np.zeros(len(healthy_images))  # Label 0 for Healthy\n",
        "whitefly_labels = np.ones(len(whitefly_images))   # Label 1 for Whitefly\n",
        "\n",
        "# Concatenate images and labels\n",
        "all_images = np.array(healthy_images + whitefly_images)\n",
        "all_labels = np.concatenate((healthy_labels, whitefly_labels))\n",
        "\n",
        "print(f\"Shape of all_images: {all_images.shape}\")\n",
        "print(f\"Shape of all_labels: {all_labels.shape}\")\n",
        "\n",
        "# Split the data into training and temporary sets (70% train, 30% temporary)\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Split the temporary set into validation (10% of original) and test (20% of original)\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_temp, y_temp, test_size=0.6667, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(f\"Shape of training images: {x_train.shape}\")\n",
        "print(f\"Shape of training labels: {y_train.shape}\")\n",
        "print(f\"Shape of validation images: {x_val.shape}\")\n",
        "print(f\"Shape of validation labels: {y_val.shape}\")\n",
        "print(f\"Shape of test images: {x_test.shape}\")\n",
        "print(f\"Shape of test labels: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSjG4L5-uK7a"
      },
      "source": [
        "LOAD AND PREPROCESS DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQCb1PBDG4Dz"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(directory, target_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses images from a directory, handling corrupted files.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Path to the directory containing images.\n",
        "        target_size (tuple): Desired size for resizing images (width, height).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of preprocessed image arrays.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img = img.resize(target_size)\n",
        "            img_array = np.array(img)\n",
        "            images.append(img_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading or processing image: {filename} - {e}\")\n",
        "            continue\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avRz-nYBq0MP"
      },
      "source": [
        "DATA AUGUMENTAION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6fYi5QPrIsP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Instantiate an ImageDataGenerator object for the training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create an augmented data generator for the training images and labels\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32, seed=42)\n",
        "\n",
        "# Instantiate an ImageDataGenerator object for the validation data (no significant augmentation)\n",
        "validation_datagen = ImageDataGenerator()\n",
        "\n",
        "# Create a data generator for the validation images and labels\n",
        "validation_generator = validation_datagen.flow(x_val, y_val, batch_size=32)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Data generators created successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2mnYTZ6kK9s"
      },
      "source": [
        "DATA SPLITTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9360fa48"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and temporary sets (70% train, 30% temporary)\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Split the temporary set into validation (10% of original) and test (20% of original)\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_temp, y_temp, test_size=0.6667, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(f\"Shape of training images: {x_train.shape}\")\n",
        "print(f\"Shape of training labels: {y_train.shape}\")\n",
        "print(f\"Shape of validation images: {x_val.shape}\")\n",
        "print(f\"Shape of validation labels: {y_val.shape}\")\n",
        "print(f\"Shape of test images: {x_test.shape}\")\n",
        "print(f\"Shape of test labels: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGUvSdJxxw0V"
      },
      "source": [
        "DISPLAY SOME PREPROCESSED IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a89ff623"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a few images and labels to display\n",
        "num_images_to_display = 6\n",
        "selected_indices = np.random.choice(len(x_train), num_images_to_display, replace=False)\n",
        "\n",
        "# Create a figure and subplots to display the images\n",
        "fig, axes = plt.subplots(1, num_images_to_display, figsize=(15, 5))\n",
        "\n",
        "# Iterate through the selected images and display them\n",
        "for i, idx in enumerate(selected_indices):\n",
        "    image = x_train[idx]\n",
        "    label = y_train[idx]\n",
        "\n",
        "    # Display the image\n",
        "    axes[i].imshow(image)\n",
        "\n",
        "    # Set the title based on the label\n",
        "    if label == 0:\n",
        "        axes[i].set_title(\"Healthy\")\n",
        "    else:\n",
        "        axes[i].set_title(\"Whitefly\")\n",
        "\n",
        "    # Turn off the axis\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# Adjust layout and display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yse67PV0sICg"
      },
      "source": [
        "CLASS DISTRIBUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8MTdJ0JsXX_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Combine all labels to get the overall distribution\n",
        "all_labels_combined = np.concatenate((y_train, y_val, y_test))\n",
        "\n",
        "# Count the occurrences of each class\n",
        "class_counts = pd.Series(all_labels_combined).value_counts()\n",
        "\n",
        "# Map numerical labels to class names for better readability\n",
        "class_names = {0: 'Healthy', 1: 'Whitefly'}\n",
        "class_counts.index = class_counts.index.map(class_names)\n",
        "\n",
        "# Plot the class distribution\n",
        "plt.figure(figsize=(7, 5))\n",
        "ax = sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')\n",
        "plt.title('Overall Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "\n",
        "# Add count labels on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{int(p.get_height())}',\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center',\n",
        "                xytext=(0, 9),\n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR71726DtnvQ"
      },
      "source": [
        "SMART CALLBACKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92dtGCvzzkPv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# ModelCheckpoint to save the best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',  # Filename to save the model\n",
        "    monitor='val_accuracy',  # Metric to monitor\n",
        "    save_best_only=True,     # Save only the best model\n",
        "    mode='max',              # Maximize validation accuracy\n",
        "    verbose=1                # Log when a new best model is saved\n",
        ")\n",
        "\n",
        "# ReduceLROnPlateau to reduce learning rate when a metric has stopped improving\n",
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',      # Metric to monitor\n",
        "    factor=0.2,              # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
        "    patience=5,              # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    min_lr=0.0001,           # Lower bound on the learning rate\n",
        "    verbose=1                # Log when learning rate is reduced\n",
        ")\n",
        "\n",
        "# EarlyStopping to stop training when a monitored metric has stopped improving\n",
        "early_stopper = EarlyStopping(\n",
        "    monitor='val_loss',      # Metric to monitor\n",
        "    patience=10,             # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True, # Restore model weights from the epoch with the best value of the monitored metric\n",
        "    verbose=1                # Log when training stops early\n",
        ")\n",
        "\n",
        "# Combine all callbacks into a list\n",
        "callbacks = [checkpoint, lr_reducer, early_stopper]\n",
        "\n",
        "print(\"Smart callbacks (ModelCheckpoint, ReduceLROnPlateau, EarlyStopping) initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GQDwmXaucPP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNSTK0QKkgP9"
      },
      "source": [
        "BUILDING CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9a8b47c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Initialize the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add convolutional and pooling layers with BatchNormalization and Dropout\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25)) # Adding dropout after first pooling layer\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25)) # Adding dropout after second pooling layer\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25)) # Adding dropout after third pooling layer\n",
        "\n",
        "# Flatten the output\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add dense layers with BatchNormalization and Dropout\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5)) # Adding dropout before final dense layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0XZNNzYlKF7"
      },
      "source": [
        "COMPILE THE CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daf31b9c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59d2edf6"
      },
      "outputs": [],
      "source": [
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = x_train.shape[0] // 32\n",
        "validation_steps = x_val.shape[0] // 32\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=100, # Set a large number of epochs, EarlyStopping will determine the actual number\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks # Use the defined callbacks, including EarlyStopping\n",
        ")\n",
        "\n",
        "print(\"Model training completed (or stopped early by EarlyStopping callback).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYiIp5sMzFOm"
      },
      "source": [
        "TRAINING THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXyb-b3BGDCM"
      },
      "source": [
        "RUN THE CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJoUxuzzGQCU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, fbeta_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Get predictions for the test set from the CNN model\n",
        "y_pred_cnn_probabilities = model.predict(x_test)\n",
        "y_pred_cnn = (y_pred_cnn_probabilities > 0.5).astype(\"int32\")\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate additional metrics\n",
        "precision = precision_score(y_test, y_pred_cnn)\n",
        "recall = recall_score(y_test, y_pred_cnn)\n",
        "f2 = fbeta_score(y_test, y_pred_cnn, beta=2) # Beta=2 for F2-score\n",
        "\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1-Score: {f2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSLhbi4d_ZGa"
      },
      "source": [
        "PERFORMANCE METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF4yyDuC-M36"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ensure y_pred_cnn is generated from the CNN model prediction\n",
        "# This should have been calculated in cell 'uJoUxuzzGQCU'\n",
        "# If not, re-run model.predict\n",
        "if 'y_pred_cnn' not in globals():\n",
        "    print(\"y_pred_cnn not found. Running model prediction on x_test...\")\n",
        "    y_pred_cnn_probabilities = model.predict(x_test)\n",
        "    y_pred_cnn = (y_pred_cnn_probabilities > 0.5).astype(\"int32\")\n",
        "\n",
        "# CNN metrics (accuracy is already available as 'accuracy' from model.evaluate())\n",
        "cnn_precision = precision_score(y_test, y_pred_cnn)\n",
        "cnn_recall = recall_score(y_test, y_pred_cnn)\n",
        "cnn_f1 = f1_score(y_test, y_pred_cnn)\n",
        "cnn_accuracy = accuracy # This variable 'accuracy' is from the model.evaluate() call for CNN\n",
        "\n",
        "# Create a DataFrame for CNN metrics to easily plot\n",
        "metrics_data = {\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "    'Value': [cnn_accuracy, cnn_precision, cnn_recall, cnn_f1]\n",
        "}\n",
        "cnn_metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Plot the metrics as a bar graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Metric', y='Value', data=cnn_metrics_df, palette='viridis')\n",
        "plt.ylim(0, 1) # Metrics are between 0 and 1\n",
        "plt.title('CNN Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metric')\n",
        "\n",
        "# Add value labels on top of the bars\n",
        "for index, row in cnn_metrics_df.iterrows():\n",
        "    plt.text(index, row.Value + 0.02, round(row.Value, 4), color='black', ha=\"center\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"CNN Model Performance Metrics (Bar Graph):\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OorgEsWZ6JYS"
      },
      "source": [
        "CONFUSION MATRIX FOR CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGZeqZBm6cwc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Ensure y_pred_cnn is generated by the model.predict step (uJoUxuzzGQCU)\n",
        "# If it hasn't been run, y_pred_cnn will be undefined.\n",
        "# For safety, re-calculate y_pred_cnn if needed, assuming x_test and model are available.\n",
        "if 'y_pred_cnn' not in globals():\n",
        "    print(\"y_pred_cnn not found. Running model prediction on x_test...\")\n",
        "    y_pred_cnn_probabilities = model.predict(x_test)\n",
        "    y_pred_cnn = (y_pred_cnn_probabilities > 0.5).astype(\"int32\")\n",
        "\n",
        "# Generate the confusion matrix for the CNN model\n",
        "cm_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
        "\n",
        "# Display the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Healthy', 'Whitefly'], yticklabels=['Healthy', 'Whitefly'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for CNN Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7RP9yi99KyZ"
      },
      "source": [
        "ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScCIWH_G9RoM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class (Whitefly) from the CNN model\n",
        "# y_pred_cnn_probabilities is already available from cell uJoUxuzzGQCU\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_cnn_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for CNN Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC Curve generated with AUC: {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWAWSgFEa7rg"
      },
      "source": [
        "OTHER METRICS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBLbjLgig6Nd"
      },
      "source": [
        "SUPPORT VECTOR MACHINE                              \n",
        "FEATURE EXTRACTION FOR SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a5fc6ad"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Create a new model that outputs the features from the last convolutional layer\n",
        "feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
        "\n",
        "# Function to extract features from a dataset\n",
        "def extract_features(dataset, model):\n",
        "    features = model.predict(dataset)\n",
        "    return features.reshape(features.shape[0], -1) # Flatten the features\n",
        "\n",
        "# Extract features for training, validation, and test sets\n",
        "x_train_features = extract_features(x_train, feature_extractor)\n",
        "x_val_features = extract_features(x_val, feature_extractor)\n",
        "x_test_features = extract_features(x_test, feature_extractor)\n",
        "\n",
        "print(\"Features extracted successfully.\")\n",
        "print(f\"Shape of training features: {x_train_features.shape}\")\n",
        "print(f\"Shape of validation features: {x_val_features.shape}\")\n",
        "print(f\"Shape of test features: {x_test_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oTXDlTvdnZW"
      },
      "source": [
        "SUPPORT VECTOR MACHINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "682458e5"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Initialize the Support Vector Machine classifier\n",
        "svm_classifier = SVC(kernel='linear', random_state=42) # You can experiment with kernel='rbf'\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the validation set (optional)\n",
        "y_val_pred_svm = svm_classifier.predict(x_val_features)\n",
        "svm_val_accuracy = accuracy_score(y_val, y_val_pred_svm)\n",
        "print(f\"SVM Validation Accuracy: {svm_val_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the SVM classifier on the test set\n",
        "y_test_pred_svm = svm_classifier.predict(x_test_features)\n",
        "svm_accuracy = accuracy_score(y_test, y_test_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_test_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_test_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_test_pred_svm)\n",
        "\n",
        "print(f\"SVM Test Accuracy: {svm_accuracy:.4f}\")\n",
        "print(f\"SVM Test Precision: {svm_precision:.4f}\")\n",
        "print(f\"SVM Test Recall: {svm_recall:.4f}\")\n",
        "print(f\"SVM Test F1-Score: {svm_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtcJxl26V6oS"
      },
      "source": [
        "CONFUSION MATRIX FOR SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzDaxUbrVCTg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate the confusion matrix for the SVM model\n",
        "cm_svm = confusion_matrix(y_test, y_test_pred_svm)\n",
        "\n",
        "# Display the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=['Healthy', 'Whitefly'], yticklabels=['Healthy', 'Whitefly'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for SVM Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jkElBj6Gw_p"
      },
      "source": [
        "ROC CURVE FOR SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv9XbTXjGo0Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC # Import SVC again\n",
        "\n",
        "# --- Retrain SVM with probability=True to get probability scores for ROC curve ---\n",
        "print(\"Retraining SVM with probability=True for ROC curve generation...\")\n",
        "svm_classifier_proba = SVC(kernel='linear', random_state=42, probability=True)\n",
        "svm_classifier_proba.fit(x_train_features, y_train)\n",
        "\n",
        "# Get predicted probabilities for the positive class (Whitefly) from the SVM model\n",
        "y_pred_svm_probabilities = svm_classifier_proba.predict_proba(x_test_features)[:, 1] # Get probabilities for the positive class (label 1)\n",
        "\n",
        "# Calculate ROC curve and AUC for SVM\n",
        "fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_pred_svm_probabilities)\n",
        "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
        "\n",
        "# Plot the ROC curve for SVM\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_svm)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for SVM Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC Curve for SVM generated with AUC: {roc_auc_svm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppDY1ZyimHsP"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veqZW30ml9eJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42) # You can adjust n_estimators\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf_classifier.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the validation set (optional)\n",
        "y_val_pred_rf = rf_classifier.predict(x_val_features)\n",
        "rf_val_accuracy = accuracy_score(y_val, y_val_pred_rf)\n",
        "print(f\"Random Forest Validation Accuracy: {rf_val_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the Random Forest classifier on the test set\n",
        "y_test_pred_rf = rf_classifier.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_test_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_test_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_test_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_test_pred_rf)\n",
        "\n",
        "print(f\"Random Forest Test Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Random Forest Test Precision: {rf_precision:.4f}\")\n",
        "print(f\"Random Forest Test Recall: {rf_recall:.4f}\")\n",
        "print(f\"Random Forest Test F1-Score: {rf_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLaxmyoLVr60"
      },
      "source": [
        "CONFUSION MATRIX FOR RABDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_1j8zF1NA_W"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate the confusion matrix for the Random Forest model\n",
        "cm_rf = confusion_matrix(y_test, y_test_pred_rf)\n",
        "\n",
        "# Display the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['Healthy', 'Whitefly'], yticklabels=['Healthy', 'Whitefly'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Random Forest Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7KsKMzYfy7m"
      },
      "source": [
        "ROC OF RANOM FORST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbPUGydKHfMl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure the Random Forest classifier is trained and features are extracted.\n",
        "# If rf_classifier or x_test_features are not defined, you might need to run previous cells.\n",
        "\n",
        "# Get predicted probabilities for the positive class (Whitefly) from the Random Forest model\n",
        "# RandomForestClassifier inherently supports predict_proba\n",
        "if 'rf_classifier' not in globals() or 'x_test_features' not in globals():\n",
        "    print(\"Random Forest classifier or test features not found. Please ensure the SVM and Random Forest training cells (e.g., veqZW30ml9eJ and 7a5fc6ad) have been run.\")\n",
        "    # Optionally, re-run necessary parts or provide instructions.\n",
        "    # For this execution, assuming they are available from previous steps.\n",
        "\n",
        "y_pred_rf_probabilities = rf_classifier.predict_proba(x_test_features)[:, 1] # Get probabilities for the positive class (label 1)\n",
        "\n",
        "# Calculate ROC curve and AUC for Random Forest\n",
        "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_rf_probabilities)\n",
        "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "\n",
        "# Plot the ROC curve for Random Forest\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_rf, tpr_rf, color='darkgreen', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_rf)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Random Forest Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC Curve for Random Forest generated with AUC: {roc_auc_rf:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqVz-dItIGfb"
      },
      "source": [
        "LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePh7DzubHxeP"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Ensure x_train_features and x_test_features are defined from previous steps.\n",
        "# If not, run the feature extraction cell (7a5fc6ad) first.\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression(random_state=42, solver='liblinear') # 'liblinear' is a good choice for small datasets and binary classification\n",
        "\n",
        "print(\"Training Logistic Regression classifier...\")\n",
        "\n",
        "# Train the Logistic Regression classifier\n",
        "lr_classifier.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the validation set (optional)\n",
        "y_val_pred_lr = lr_classifier.predict(x_val_features)\n",
        "lr_val_accuracy = accuracy_score(y_val, y_val_pred_lr)\n",
        "print(f\"Logistic Regression Validation Accuracy: {lr_val_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the Logistic Regression classifier on the test set\n",
        "y_test_pred_lr = lr_classifier.predict(x_test_features)\n",
        "lr_accuracy = accuracy_score(y_test, y_test_pred_lr)\n",
        "lr_precision = precision_score(y_test, y_test_pred_lr)\n",
        "lr_recall = recall_score(y_test, y_test_pred_lr)\n",
        "lr_f1 = f1_score(y_test, y_test_pred_lr)\n",
        "\n",
        "print(f\"Logistic Regression Test Accuracy: {lr_accuracy:.4f}\")\n",
        "print(f\"Logistic Regression Test Precision: {lr_precision:.4f}\")\n",
        "print(f\"Logistic Regression Test Recall: {lr_recall:.4f}\")\n",
        "print(f\"Logistic Regression Test F1-Score: {lr_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upph_BYEIaCb"
      },
      "source": [
        "CONFUSSION MATRIX FOR LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TphauaEN02B7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Ensure y_test_pred_lr is generated by the Logistic Regression training step (ePh7DzubHxeP)\n",
        "# If not, re-run that cell first.\n",
        "if 'y_test_pred_lr' not in globals():\n",
        "    print(\"y_test_pred_lr not found. Please run the Logistic Regression training cell (ePh7DzubHxeP) first.\")\n",
        "else:\n",
        "    # Generate the confusion matrix for the Logistic Regression model\n",
        "    cm_lr = confusion_matrix(y_test, y_test_pred_lr)\n",
        "\n",
        "    # Display the confusion matrix using seaborn\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Healthy', 'Whitefly'], yticklabels=['Healthy', 'Whitefly'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix for Logistic Regression Model')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDvaziOLIr8j"
      },
      "source": [
        "ROC CURVE FOR  LOGISTIC RGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91oqXHmFIsvD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure lr_classifier and x_test_features are defined from previous steps.\n",
        "# If not, please run the Logistic Regression training cell (ePh7DzubHxeP) and feature extraction cell (7a5fc6ad) first.\n",
        "\n",
        "# Get predicted probabilities for the positive class (Whitefly) from the Logistic Regression model\n",
        "y_pred_lr_probabilities = lr_classifier.predict_proba(x_test_features)[:, 1] # Get probabilities for the positive class (label 1)\n",
        "\n",
        "# Calculate ROC curve and AUC for Logistic Regression\n",
        "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_lr_probabilities)\n",
        "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "\n",
        "# Plot the ROC curve for Logistic Regression\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_lr)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Logistic Regression Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC Curve for Logistic Regression with AUC: {roc_auc_lr:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcbyyTY7JO4r"
      },
      "source": [
        "MODEL COMPARISONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDslGct6JZWv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# --- Re-extract features if necessary for robustness ---\n",
        "# This block ensures x_train_features, x_val_features, x_test_features are available\n",
        "# It's copied here for robustness in case previous feature extraction cells were not run\n",
        "if 'feature_extractor' not in globals():\n",
        "    print(\"Loading VGG16 for feature extraction...\")\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "    feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
        "\n",
        "def extract_features(dataset, model):\n",
        "    features = model.predict(dataset)\n",
        "    return features.reshape(features.shape[0], -1) # Flatten the features\n",
        "\n",
        "if 'x_train_features' not in globals():\n",
        "    print(\"Extracting features for all sets...\")\n",
        "    x_train_features = extract_features(x_train, feature_extractor)\n",
        "    x_val_features = extract_features(x_val, feature_extractor)\n",
        "    x_test_features = extract_features(x_test, feature_extractor)\n",
        "\n",
        "# --- Ensure all models are trained and their metrics are available ---\n",
        "\n",
        "# CNN Metrics\n",
        "cnn_accuracy = accuracy # from model.evaluate()\n",
        "cnn_precision = precision_score(y_test, y_pred_cnn)\n",
        "cnn_recall = recall_score(y_test, y_pred_cnn)\n",
        "cnn_f1 = f1_score(y_test, y_pred_cnn)\n",
        "\n",
        "# SVM Metrics\n",
        "if 'svm_classifier' not in globals():\n",
        "    print(\"Training SVM classifier...\")\n",
        "    svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "    svm_classifier.fit(x_train_features, y_train)\n",
        "y_test_pred_svm = svm_classifier.predict(x_test_features)\n",
        "svm_accuracy = accuracy_score(y_test, y_test_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_test_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_test_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_test_pred_svm)\n",
        "\n",
        "# Random Forest Metrics\n",
        "if 'rf_classifier' not in globals():\n",
        "    print(\"Training Random Forest classifier...\")\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_classifier.fit(x_train_features, y_train)\n",
        "y_test_pred_rf = rf_classifier.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_test_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_test_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_test_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_test_pred_rf)\n",
        "\n",
        "# Logistic Regression Metrics\n",
        "if 'lr_classifier' not in globals():\n",
        "    print(\"Training Logistic Regression classifier...\")\n",
        "    lr_classifier = LogisticRegression(random_state=42, solver='liblinear')\n",
        "    lr_classifier.fit(x_train_features, y_train)\n",
        "y_test_pred_lr = lr_classifier.predict(x_test_features)\n",
        "lr_accuracy = accuracy_score(y_test, y_test_pred_lr)\n",
        "lr_precision = precision_score(y_test, y_test_pred_lr)\n",
        "lr_recall = recall_score(y_test, y_test_pred_lr)\n",
        "lr_f1 = f1_score(y_test, y_test_pred_lr)\n",
        "\n",
        "# Create a DataFrame for all metrics\n",
        "metrics_data = {\n",
        "    'Model': ['CNN', 'SVM', 'Random Forest', 'Logistic Regression'],\n",
        "    'Accuracy': [cnn_accuracy, svm_accuracy, rf_accuracy, lr_accuracy],\n",
        "    'Precision': [cnn_precision, svm_precision, rf_precision, lr_precision],\n",
        "    'Recall': [cnn_recall, svm_recall, rf_recall, lr_recall],\n",
        "    'F1-Score': [cnn_f1, svm_f1, rf_f1, lr_f1]\n",
        "}\n",
        "metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Melt the DataFrame for easy plotting with seaborn\n",
        "metrics_melted = metrics_df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
        "\n",
        "# Create a grouped bar chart\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='Metric', y='Score', hue='Model', data=metrics_melted, palette='deep')\n",
        "plt.ylim(0.9, 1.0) # Set y-axis limit to highlight differences\n",
        "plt.title('Comparison of Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metric')\n",
        "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1LK5mygM2xT"
      },
      "source": [
        "TABULAR RESULTS FOR THE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvL3UwNxKdhT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure metrics_df is available from the previous comparison cell (HDslGct6JZWv)\n",
        "if 'metrics_df' in globals():\n",
        "    print(\"--- Model Performance Comparison Table ---\")\n",
        "    display(metrics_df)\n",
        "\n",
        "    # Identify the best algorithm based on F1-Score\n",
        "    best_model_f1 = metrics_df.loc[metrics_df['F1-Score'].idxmax()]\n",
        "    print(f\"\\nThe best algorithm based on F1-Score is: {best_model_f1['Model']} with an F1-Score of {best_model_f1['F1-Score']:.4f}\")\n",
        "\n",
        "    # Optionally, also show best based on Accuracy\n",
        "    best_model_accuracy = metrics_df.loc[metrics_df['Accuracy'].idxmax()]\n",
        "    if best_model_accuracy['Model'] != best_model_f1['Model']:\n",
        "        print(f\"The best algorithm based on Accuracy is: {best_model_accuracy['Model']} with an Accuracy of {best_model_accuracy['Accuracy']:.4f}\")\n",
        "else:\n",
        "    print(\"metrics_df not found. Please ensure the comparison cell (HDslGct6JZWv) has been run.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awBBq9k6nH1z"
      },
      "source": [
        "DATA PREPATION FOR K-FOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03c057cf"
      },
      "outputs": [],
      "source": [
        "# Combine training and validation data for K-Fold Cross-Validation\n",
        "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
        "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "# Print the shapes of the combined data\n",
        "print(f\"Shape of combined features: {x_combined.shape}\")\n",
        "print(f\"Shape of combined labels: {y_combined.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBD5_7z5m-wj"
      },
      "source": [
        "K-FOLD CROSS VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43829f97"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define the number of folds\n",
        "n_splits = 5\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store accuracy and loss for each fold\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "\n",
        "print(f\"K-Fold Cross-Validation initialized with {n_splits} splits.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jX6W4A4rU10"
      },
      "source": [
        "PERFOM K-FOLD CROSS VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1LGWOsW0rUIU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the number of epochs for K-Fold training\n",
        "kfold_epochs = 30\n",
        "\n",
        "for fold_num, (train_index, val_index) in enumerate(kf.split(x_combined, y_combined), 1):\n",
        "    print(f\"\\n--- Fold {fold_num}/{n_splits} ---\")\n",
        "\n",
        "    # Get the training and validation data for the current fold\n",
        "    x_train_fold, x_val_fold = x_combined[train_index], x_combined[val_index]\n",
        "    y_train_fold, y_val_fold = y_combined[train_index], y_combined[val_index]\n",
        "\n",
        "    # Create ImageDataGenerator instances for the current fold\n",
        "    train_datagen_fold = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    validation_datagen_fold = ImageDataGenerator()\n",
        "\n",
        "    train_generator_fold = train_datagen_fold.flow(x_train_fold, y_train_fold, batch_size=32, seed=42)\n",
        "    validation_generator_fold = validation_datagen_fold.flow(x_val_fold, y_val_fold, batch_size=32)\n",
        "\n",
        "    # Recreate the CNN model architecture for each fold\n",
        "    model_kfold = Sequential()\n",
        "    model_kfold.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "    model_kfold.add(BatchNormalization())\n",
        "    model_kfold.add(MaxPooling2D((2, 2)))\n",
        "    model_kfold.add(Dropout(0.25))\n",
        "\n",
        "    model_kfold.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model_kfold.add(BatchNormalization())\n",
        "    model_kfold.add(MaxPooling2D((2, 2)))\n",
        "    model_kfold.add(Dropout(0.25))\n",
        "\n",
        "    model_kfold.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model_kfold.add(BatchNormalization())\n",
        "    model_kfold.add(MaxPooling2D((2, 2)))\n",
        "    model_kfold.add(Dropout(0.25))\n",
        "\n",
        "    model_kfold.add(Flatten())\n",
        "\n",
        "    model_kfold.add(Dense(128, activation='relu'))\n",
        "    model_kfold.add(BatchNormalization())\n",
        "    model_kfold.add(Dropout(0.5))\n",
        "    model_kfold.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model_kfold.compile(optimizer=Adam(),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "    # Calculate steps per epoch and validation steps for the current fold\n",
        "    steps_per_epoch_fold = len(x_train_fold) // 32\n",
        "    validation_steps_fold = len(x_val_fold) // 32\n",
        "\n",
        "    # Train the model for the current fold\n",
        "    history_kfold = model_kfold.fit(\n",
        "        train_generator_fold,\n",
        "        steps_per_epoch=steps_per_epoch_fold,\n",
        "        epochs=kfold_epochs,\n",
        "        validation_data=validation_generator_fold,\n",
        "        validation_steps=validation_steps_fold,\n",
        "        verbose=0 # Suppress verbose output for cleaner log\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation data for the current fold\n",
        "    fold_loss, fold_accuracy = model_kfold.evaluate(x_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "    # Store the accuracy and loss for the current fold\n",
        "    fold_accuracies.append(fold_accuracy)\n",
        "    fold_losses.append(fold_loss)\n",
        "\n",
        "    print(f\"Fold {fold_num} - Validation Loss: {fold_loss:.4f}, Validation Accuracy: {fold_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nAverage K-Fold Validation Accuracy: {sum(fold_accuracies) / len(fold_accuracies):.4f}\")\n",
        "print(f\"Average K-Fold Validation Loss: {sum(fold_losses) / len(fold_losses):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIvQC4FkSFvk"
      },
      "source": [
        "MODEL VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXFoWfucSKzc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtwcwWy9S92D"
      },
      "source": [
        "SAMPLE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlZmD7KyTBaa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Select a few random images from the test set\n",
        "num_samples = 5\n",
        "random_indices = np.random.choice(len(x_test), num_samples, replace=False)\n",
        "\n",
        "# Get the selected sample images, true labels, and predictions\n",
        "sample_images = x_test[random_indices]\n",
        "sample_true_labels = y_test[random_indices]\n",
        "sample_predictions = model.predict(sample_images)\n",
        "\n",
        "# Convert predictions to class labels (0 or 1)\n",
        "sample_predicted_labels = (sample_predictions > 0.5).astype(\"int32\")\n",
        "\n",
        "# Create a figure and subplots to display the samples\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(1, num_samples, i + 1)\n",
        "    plt.imshow(sample_images[i])\n",
        "    true_label = \"Healthy\" if sample_true_labels[i] == 0 else \"Whitefly\"\n",
        "    predicted_label = \"Healthy\" if sample_predicted_labels[i] == 0 else \"Whitefly\"\n",
        "    plt.title(f\"True: {true_label}\\nPredicted: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru-jN-jAu9PQ"
      },
      "source": [
        "LOAD AND PREPROCESS  THE NEW IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "210908f0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the best saved model\n",
        "loaded_model = tf.keras.models.load_model('best_model.keras')\n",
        "\n",
        "print(\"Model 'best_model.keras' loaded successfully.\")\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcfef9fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# 1. Correct file path (MUST use raw string r\"\" on Windows)\n",
        "new_image_path = r\"/content/downloa3.webp\"\n",
        "\n",
        "# 2. Check if the file exists\n",
        "if not os.path.exists(new_image_path):\n",
        "    raise FileNotFoundError(f\"Image not found at: {new_image_path}\")\n",
        "\n",
        "# 3. Load the image\n",
        "img = Image.open(new_image_path)\n",
        "\n",
        "# Convert to RGB (very IMPORTANT)\n",
        "img = img.convert(\"RGB\")\n",
        "\n",
        "# 4. Resize image\n",
        "target_size = (128, 128)\n",
        "img_resized = img.resize(target_size)\n",
        "\n",
        "# 5. Convert to NumPy array\n",
        "img_array = np.array(img_resized)\n",
        "\n",
        "# 6. Normalize pixels (0255  01)\n",
        "img_array = img_array.astype(\"float32\") / 255.0\n",
        "\n",
        "# 7. Add batch dimension\n",
        "img_processed = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "print(f\"Original image size: {img.size}\")\n",
        "print(f\"Resized image size: {img_resized.size}\")\n",
        "print(f\"Final input shape for model: {img_processed.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ebb338b"
      },
      "source": [
        "Finally, we use the loaded model to make a prediction on the preprocessed image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fea969c"
      },
      "outputs": [],
      "source": [
        "# Make prediction\n",
        "prediction = loaded_model.predict(img_processed)\n",
        "\n",
        "# Interpret the prediction\n",
        "predicted_class = \"Whitefly\" if prediction[0][0] > 0.5 else \"Healthy\"\n",
        "confidence = prediction[0][0] if prediction[0][0] > 0.5 else (1 - prediction[0][0])\n",
        "\n",
        "print(f\"The processed image is predicted as: {predicted_class} (Confidence: {confidence:.2%})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}